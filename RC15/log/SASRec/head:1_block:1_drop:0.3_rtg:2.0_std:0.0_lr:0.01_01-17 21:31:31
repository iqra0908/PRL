WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:157: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:74: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:78: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
WARNING:tensorflow:From /Users/xin/miniconda3/envs/tf-1.15/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:84: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:142: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:163: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:223: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:153: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:279: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:282: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:284: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

INFO:root:the loss in 200th batch is: 1.953147
INFO:root:the loss in 400th batch is: 1.830909
INFO:root:the loss in 600th batch is: 1.671029
INFO:root:the loss in 800th batch is: 1.626289
INFO:root:the loss in 1000th batch is: 1.572465
INFO:root:the loss in 1200th batch is: 1.526216
INFO:root:the loss in 1400th batch is: 1.525590
INFO:root:the loss in 1600th batch is: 1.428978
INFO:root:the loss in 1800th batch is: 1.450302
INFO:root:the loss in 2000th batch is: 1.448292
INFO:root:#############################################################
INFO:root:total clicks: 108416, total purchase:4245
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 1: 2650.800000
INFO:root:clicks hr ndcg @ 1 : 0.091813, 0.091813
INFO:root:purchase hr and ndcg @1 : 0.155477, 0.155477
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 5: 7189.400000
INFO:root:clicks hr ndcg @ 5 : 0.252241, 0.174544
INFO:root:purchase hr and ndcg @5 : 0.405183, 0.284773
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 10: 9500.000000
INFO:root:clicks hr ndcg @ 10 : 0.336389, 0.201804
INFO:root:purchase hr and ndcg @10 : 0.519670, 0.322297
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 20: 11489.800000
INFO:root:clicks hr ndcg @ 20 : 0.411092, 0.220749
INFO:root:purchase hr and ndcg @20 : 0.606832, 0.344417
INFO:root:#############################################################
INFO:root:the loss in 2200th batch is: 1.355086
INFO:root:the loss in 2400th batch is: 1.424593
INFO:root:the loss in 2600th batch is: 1.405464
INFO:root:the loss in 2800th batch is: 1.320976
INFO:root:the loss in 3000th batch is: 1.376151
INFO:root:the loss in 3200th batch is: 1.461722
INFO:root:the loss in 3400th batch is: 1.366333
INFO:root:the loss in 3600th batch is: 1.511377
INFO:root:the loss in 3800th batch is: 1.245896
INFO:root:the loss in 4000th batch is: 1.332181
INFO:root:#############################################################
INFO:root:total clicks: 108416, total purchase:4245
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 1: 2963.400000
INFO:root:clicks hr ndcg @ 1 : 0.101341, 0.101341
INFO:root:purchase hr and ndcg @1 : 0.180448, 0.180448
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 5: 8004.800000
INFO:root:clicks hr ndcg @ 5 : 0.281868, 0.194357
INFO:root:purchase hr and ndcg @5 : 0.445936, 0.317672
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 10: 10436.600000
INFO:root:clicks hr ndcg @ 10 : 0.371421, 0.223375
INFO:root:purchase hr and ndcg @10 : 0.561366, 0.354964
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 20: 12548.000000
INFO:root:clicks hr ndcg @ 20 : 0.450441, 0.243435
INFO:root:purchase hr and ndcg @20 : 0.655124, 0.378942
INFO:root:#############################################################
INFO:root:the loss in 4200th batch is: 1.317236
INFO:root:the loss in 4400th batch is: 1.245367
INFO:root:the loss in 4600th batch is: 1.194981
INFO:root:the loss in 4800th batch is: 1.490147
INFO:root:the loss in 5000th batch is: 1.332995
INFO:root:the loss in 5200th batch is: 1.191833
INFO:root:the loss in 5400th batch is: 1.272912
INFO:root:the loss in 5600th batch is: 1.241367
INFO:root:the loss in 5800th batch is: 1.290332
INFO:root:the loss in 6000th batch is: 1.162574
