WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:155: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:74: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:84: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:94: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:142: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /Users/xin/miniconda3/envs/tf-1.15/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:163: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:184: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRecModules.py:223: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv1D` instead.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:151: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:277: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:280: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /Users/xin/Documents/RL4REC/RC15/SASRec_PRL.py:282: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

INFO:root:the loss in 200th batch is: 1.864646
INFO:root:the loss in 400th batch is: 1.682570
INFO:root:the loss in 600th batch is: 1.494687
INFO:root:the loss in 800th batch is: 1.440664
INFO:root:the loss in 1000th batch is: 1.435050
INFO:root:the loss in 1200th batch is: 1.358368
INFO:root:the loss in 1400th batch is: 1.413722
INFO:root:the loss in 1600th batch is: 1.324694
INFO:root:the loss in 1800th batch is: 1.339218
INFO:root:the loss in 2000th batch is: 1.290054
INFO:root:#############################################################
INFO:root:total clicks: 108416, total purchase:4245
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 1: 2825.600000
INFO:root:clicks hr ndcg @ 1 : 0.096277, 0.096277
INFO:root:purchase hr and ndcg @1 : 0.173852, 0.173852
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 5: 7698.000000
INFO:root:clicks hr ndcg @ 5 : 0.270809, 0.186117
INFO:root:purchase hr and ndcg @5 : 0.430153, 0.307037
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 10: 10037.600000
INFO:root:clicks hr ndcg @ 10 : 0.357263, 0.214169
INFO:root:purchase hr and ndcg @10 : 0.539694, 0.342619
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 20: 12000.800000
INFO:root:clicks hr ndcg @ 20 : 0.429402, 0.232458
INFO:root:purchase hr and ndcg @20 : 0.633687, 0.366442
INFO:root:#############################################################
INFO:root:the loss in 2200th batch is: 1.398047
INFO:root:the loss in 2400th batch is: 1.262500
INFO:root:the loss in 2600th batch is: 1.321088
INFO:root:the loss in 2800th batch is: 1.236716
INFO:root:the loss in 3000th batch is: 1.316343
INFO:root:the loss in 3200th batch is: 1.291228
INFO:root:the loss in 3400th batch is: 1.279944
INFO:root:the loss in 3600th batch is: 1.291705
INFO:root:the loss in 3800th batch is: 1.209115
INFO:root:the loss in 4000th batch is: 1.187565
INFO:root:#############################################################
INFO:root:total clicks: 108416, total purchase:4245
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 1: 3015.200000
INFO:root:clicks hr ndcg @ 1 : 0.104191, 0.104191
INFO:root:purchase hr and ndcg @1 : 0.178092, 0.178092
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 5: 8175.000000
INFO:root:clicks hr ndcg @ 5 : 0.291101, 0.200648
INFO:root:purchase hr and ndcg @5 : 0.438869, 0.314264
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 10: 10647.600000
INFO:root:clicks hr ndcg @ 10 : 0.382213, 0.230207
INFO:root:purchase hr and ndcg @10 : 0.555948, 0.352315
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 20: 12761.400000
INFO:root:clicks hr ndcg @ 20 : 0.460652, 0.250120
INFO:root:purchase hr and ndcg @20 : 0.653239, 0.376971
INFO:root:#############################################################
INFO:root:the loss in 4200th batch is: 1.222859
INFO:root:the loss in 4400th batch is: 1.286020
INFO:root:the loss in 4600th batch is: 1.283976
INFO:root:the loss in 4800th batch is: 1.188082
INFO:root:the loss in 5000th batch is: 1.204726
INFO:root:the loss in 5200th batch is: 1.188592
INFO:root:the loss in 5400th batch is: 1.192582
INFO:root:the loss in 5600th batch is: 1.238804
INFO:root:the loss in 5800th batch is: 1.213928
INFO:root:the loss in 6000th batch is: 1.180215
INFO:root:#############################################################
INFO:root:total clicks: 108416, total purchase:4245
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 1: 3106.200000
INFO:root:clicks hr ndcg @ 1 : 0.107881, 0.107881
INFO:root:purchase hr and ndcg @1 : 0.180683, 0.180683
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 5: 8352.200000
INFO:root:clicks hr ndcg @ 5 : 0.295722, 0.204751
INFO:root:purchase hr and ndcg @5 : 0.457008, 0.323544
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 10: 10876.200000
INFO:root:clicks hr ndcg @ 10 : 0.389758, 0.235241
INFO:root:purchase hr and ndcg @10 : 0.571260, 0.360608
INFO:root:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO:root:cumulative reward @ 20: 12999.000000
INFO:root:clicks hr ndcg @ 20 : 0.470549, 0.255710
INFO:root:purchase hr and ndcg @20 : 0.658657, 0.382838
INFO:root:#############################################################
INFO:root:the loss in 6200th batch is: 1.208891
INFO:root:the loss in 6400th batch is: 1.164686
INFO:root:the loss in 6600th batch is: 1.160237
INFO:root:the loss in 6800th batch is: 1.209321
INFO:root:the loss in 7000th batch is: 1.204478
INFO:root:the loss in 7200th batch is: 1.123764
INFO:root:the loss in 7400th batch is: 1.145979
INFO:root:the loss in 7600th batch is: 1.256025
